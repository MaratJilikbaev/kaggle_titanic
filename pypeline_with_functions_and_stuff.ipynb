{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', index_col='PassengerId')\n",
    "df_test = pd.read_csv('test.csv', index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_name_part_from_df(df, col_name='Name', want_to_add_parts=['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Dr.'], missing_name_part='no_name_part'):\n",
    "    dict_name_parts = {}\n",
    "    for name in df[col_name]:\n",
    "        name_parts = name.split(' ')\n",
    "        for name_part in name_parts:\n",
    "            if name_part not in dict_name_parts.keys():\n",
    "                dict_name_parts[name_part] = 1\n",
    "            else:\n",
    "                dict_name_parts[name_part] += 1\n",
    "    \n",
    "    df_name_parts = pd.DataFrame.from_dict(dict_name_parts, orient='index')\n",
    "    df_name_parts = df_name_parts.reset_index()\n",
    "    df_name_parts.columns = ['name_part', 'cnt']\n",
    "    \n",
    "    name_part_to_df = []\n",
    "\n",
    "    for p_name in df[col_name]:\n",
    "        counter = 0\n",
    "        for name_part in want_to_add_parts:\n",
    "            if name_part in p_name:\n",
    "                name_part_to_df.append(name_part)\n",
    "                continue\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter == len(want_to_add_parts):\n",
    "                    name_part_to_df.append(missing_name_part)\n",
    "                    \n",
    "    return name_part_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_data_to_df(df, list_of_cols_to_add, list_of_names_of_cols_to_add):\n",
    "    for col_index in range(len(list_of_cols_to_add)):\n",
    "        col = list_of_cols_to_add[col_index]\n",
    "        col_name = list_of_names_of_cols_to_add[col_index]\n",
    "        df[col_name] = col\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_for_model(df):\n",
    "\n",
    "    list_of_cols_to_add = []\n",
    "    list_of_names_of_cols_to_add = []\n",
    "\n",
    "    name_parts = take_name_part_from_df(df, col_name='Name', want_to_add_parts=['Mr.', 'Mrs.', 'Miss.', 'Master.', 'Dr.'], missing_name_part='no_name_part')\n",
    "    list_of_cols_to_add.append(name_parts)\n",
    "    list_of_names_of_cols_to_add.append('name_part')\n",
    "\n",
    "    cab_num_for_df = []\n",
    "    for cab_num in df.Cabin:\n",
    "        if pd.isna(cab_num):\n",
    "            cab_num_for_df.append('N')\n",
    "        else:\n",
    "            cab_num_for_df.append(cab_num.split(' ')[0][0])\n",
    "    list_of_cols_to_add.append(cab_num_for_df)\n",
    "    list_of_names_of_cols_to_add.append('cabin_letter')\n",
    "\n",
    "    list_of_cols_to_add.append(df['Sex'].map({'male':0, 'female':1}))\n",
    "    list_of_names_of_cols_to_add.append('sex_binary')\n",
    "    \n",
    "    df = adding_data_to_df(df, list_of_cols_to_add, list_of_names_of_cols_to_add)\n",
    "    list_of_cols_to_add = []\n",
    "    list_of_names_of_cols_to_add = []\n",
    "    \n",
    "    df['Embarked'] = df.Embarked.fillna('S')\n",
    "    mean_age_dict = df[['name_part', 'Age']].groupby('name_part').agg({'Age':'median'}).to_dict(orient='dict')['Age']\n",
    "    list_of_cols_to_add.append(df.apply(lambda row: mean_age_dict[row['name_part']] if np.isnan(row['Age']) else row['Age'], axis=1))\n",
    "    list_of_names_of_cols_to_add.append('age_no_nan')\n",
    "\n",
    "    df_for_return = adding_data_to_df(df, list_of_cols_to_add, list_of_names_of_cols_to_add)\n",
    "\n",
    "    return df_for_return\n",
    "\n",
    "df_train_for_model = transform_data_for_model(df_train)\n",
    "df_train_for_model = df_train_for_model[['Survived', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Embarked', 'name_part', 'cabin_letter', 'sex_binary', 'age_no_nan']]\n",
    "df_train_for_model = pd.get_dummies(df_train_for_model, prefix=['Embarked','name_part','cabin_letter'], columns=['Embarked','name_part','cabin_letter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from catboost import CatBoostClassifier\n",
    "import statistics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = df_train_for_model.columns[1:]\n",
    "y = df_train_for_model['Survived']\n",
    "X = df_train_for_model[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marat\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0:\tlearn: 0.4117569\ttotal: 151ms\tremaining: 15s\n",
      "1:\tlearn: 0.3970321\ttotal: 152ms\tremaining: 7.47s\n",
      "2:\tlearn: 0.3747669\ttotal: 153ms\tremaining: 4.95s\n",
      "3:\tlearn: 0.3450040\ttotal: 154ms\tremaining: 3.69s\n",
      "4:\tlearn: 0.3277946\ttotal: 155ms\tremaining: 2.94s\n",
      "5:\tlearn: 0.3209012\ttotal: 156ms\tremaining: 2.44s\n",
      "6:\tlearn: 0.3044565\ttotal: 156ms\tremaining: 2.08s\n",
      "7:\tlearn: 0.3014353\ttotal: 157ms\tremaining: 1.81s\n",
      "8:\tlearn: 0.2952029\ttotal: 158ms\tremaining: 1.6s\n",
      "9:\tlearn: 0.2737604\ttotal: 159ms\tremaining: 1.43s\n",
      "10:\tlearn: 0.2634041\ttotal: 159ms\tremaining: 1.29s\n",
      "11:\tlearn: 0.2554961\ttotal: 160ms\tremaining: 1.17s\n",
      "12:\tlearn: 0.2459044\ttotal: 161ms\tremaining: 1.08s\n",
      "13:\tlearn: 0.2374581\ttotal: 162ms\tremaining: 993ms\n",
      "14:\tlearn: 0.2294192\ttotal: 162ms\tremaining: 921ms\n",
      "15:\tlearn: 0.2239704\ttotal: 163ms\tremaining: 857ms\n",
      "16:\tlearn: 0.2212638\ttotal: 164ms\tremaining: 800ms\n",
      "17:\tlearn: 0.2128907\ttotal: 165ms\tremaining: 750ms\n",
      "18:\tlearn: 0.2023029\ttotal: 165ms\tremaining: 705ms\n",
      "19:\tlearn: 0.1976940\ttotal: 166ms\tremaining: 665ms\n",
      "20:\tlearn: 0.1924253\ttotal: 167ms\tremaining: 628ms\n",
      "21:\tlearn: 0.1851893\ttotal: 168ms\tremaining: 595ms\n",
      "22:\tlearn: 0.1837830\ttotal: 169ms\tremaining: 565ms\n",
      "23:\tlearn: 0.1782278\ttotal: 170ms\tremaining: 537ms\n",
      "24:\tlearn: 0.1738514\ttotal: 170ms\tremaining: 511ms\n",
      "25:\tlearn: 0.1719095\ttotal: 171ms\tremaining: 488ms\n",
      "26:\tlearn: 0.1645649\ttotal: 172ms\tremaining: 465ms\n",
      "27:\tlearn: 0.1619228\ttotal: 173ms\tremaining: 445ms\n",
      "28:\tlearn: 0.1554548\ttotal: 174ms\tremaining: 426ms\n",
      "29:\tlearn: 0.1488253\ttotal: 175ms\tremaining: 408ms\n",
      "30:\tlearn: 0.1455135\ttotal: 176ms\tremaining: 391ms\n",
      "31:\tlearn: 0.1376932\ttotal: 176ms\tremaining: 375ms\n",
      "32:\tlearn: 0.1334742\ttotal: 177ms\tremaining: 360ms\n",
      "33:\tlearn: 0.1288979\ttotal: 178ms\tremaining: 345ms\n",
      "34:\tlearn: 0.1271822\ttotal: 179ms\tremaining: 332ms\n",
      "35:\tlearn: 0.1233826\ttotal: 180ms\tremaining: 319ms\n",
      "36:\tlearn: 0.1211045\ttotal: 180ms\tremaining: 307ms\n",
      "37:\tlearn: 0.1193581\ttotal: 181ms\tremaining: 295ms\n",
      "38:\tlearn: 0.1149807\ttotal: 182ms\tremaining: 284ms\n",
      "39:\tlearn: 0.1136034\ttotal: 182ms\tremaining: 274ms\n",
      "40:\tlearn: 0.1116700\ttotal: 183ms\tremaining: 264ms\n",
      "41:\tlearn: 0.1093664\ttotal: 184ms\tremaining: 254ms\n",
      "42:\tlearn: 0.1084113\ttotal: 184ms\tremaining: 245ms\n",
      "43:\tlearn: 0.1075116\ttotal: 185ms\tremaining: 236ms\n",
      "44:\tlearn: 0.1058358\ttotal: 186ms\tremaining: 227ms\n",
      "45:\tlearn: 0.1047554\ttotal: 187ms\tremaining: 219ms\n",
      "46:\tlearn: 0.1035643\ttotal: 188ms\tremaining: 212ms\n",
      "47:\tlearn: 0.0996322\ttotal: 188ms\tremaining: 204ms\n",
      "48:\tlearn: 0.0969272\ttotal: 189ms\tremaining: 197ms\n",
      "49:\tlearn: 0.0953226\ttotal: 190ms\tremaining: 190ms\n",
      "50:\tlearn: 0.0935299\ttotal: 191ms\tremaining: 183ms\n",
      "51:\tlearn: 0.0913582\ttotal: 191ms\tremaining: 177ms\n",
      "52:\tlearn: 0.0895864\ttotal: 192ms\tremaining: 170ms\n",
      "53:\tlearn: 0.0876149\ttotal: 193ms\tremaining: 164ms\n",
      "54:\tlearn: 0.0868056\ttotal: 194ms\tremaining: 158ms\n",
      "55:\tlearn: 0.0857496\ttotal: 194ms\tremaining: 153ms\n",
      "56:\tlearn: 0.0839321\ttotal: 195ms\tremaining: 147ms\n",
      "57:\tlearn: 0.0829959\ttotal: 196ms\tremaining: 142ms\n",
      "58:\tlearn: 0.0818844\ttotal: 197ms\tremaining: 137ms\n",
      "59:\tlearn: 0.0805818\ttotal: 197ms\tremaining: 132ms\n",
      "60:\tlearn: 0.0796911\ttotal: 198ms\tremaining: 127ms\n",
      "61:\tlearn: 0.0786174\ttotal: 199ms\tremaining: 122ms\n",
      "62:\tlearn: 0.0769373\ttotal: 200ms\tremaining: 117ms\n",
      "63:\tlearn: 0.0765372\ttotal: 200ms\tremaining: 113ms\n",
      "64:\tlearn: 0.0753297\ttotal: 201ms\tremaining: 108ms\n",
      "65:\tlearn: 0.0747139\ttotal: 202ms\tremaining: 104ms\n",
      "66:\tlearn: 0.0722250\ttotal: 202ms\tremaining: 99.7ms\n",
      "67:\tlearn: 0.0716653\ttotal: 203ms\tremaining: 95.6ms\n",
      "68:\tlearn: 0.0707653\ttotal: 204ms\tremaining: 91.6ms\n",
      "69:\tlearn: 0.0701513\ttotal: 205ms\tremaining: 87.7ms\n",
      "70:\tlearn: 0.0696926\ttotal: 205ms\tremaining: 83.8ms\n",
      "71:\tlearn: 0.0687079\ttotal: 206ms\tremaining: 80.1ms\n",
      "72:\tlearn: 0.0676741\ttotal: 207ms\tremaining: 76.5ms\n",
      "73:\tlearn: 0.0657496\ttotal: 208ms\tremaining: 72.9ms\n",
      "74:\tlearn: 0.0653601\ttotal: 208ms\tremaining: 69.5ms\n",
      "75:\tlearn: 0.0641799\ttotal: 209ms\tremaining: 66.1ms\n",
      "76:\tlearn: 0.0635352\ttotal: 210ms\tremaining: 62.8ms\n",
      "77:\tlearn: 0.0626804\ttotal: 211ms\tremaining: 59.5ms\n",
      "78:\tlearn: 0.0618287\ttotal: 211ms\tremaining: 56.2ms\n",
      "79:\tlearn: 0.0609632\ttotal: 212ms\tremaining: 53.1ms\n",
      "80:\tlearn: 0.0592844\ttotal: 214ms\tremaining: 50.1ms\n",
      "81:\tlearn: 0.0582811\ttotal: 214ms\tremaining: 47ms\n",
      "82:\tlearn: 0.0571133\ttotal: 215ms\tremaining: 44ms\n",
      "83:\tlearn: 0.0562962\ttotal: 215ms\tremaining: 41ms\n",
      "84:\tlearn: 0.0557505\ttotal: 216ms\tremaining: 38.1ms\n",
      "85:\tlearn: 0.0553956\ttotal: 217ms\tremaining: 35.3ms\n",
      "86:\tlearn: 0.0548774\ttotal: 218ms\tremaining: 32.5ms\n",
      "87:\tlearn: 0.0546120\ttotal: 218ms\tremaining: 29.8ms\n",
      "88:\tlearn: 0.0544584\ttotal: 219ms\tremaining: 27.1ms\n",
      "89:\tlearn: 0.0533559\ttotal: 220ms\tremaining: 24.4ms\n",
      "90:\tlearn: 0.0532777\ttotal: 221ms\tremaining: 21.8ms\n",
      "91:\tlearn: 0.0526729\ttotal: 221ms\tremaining: 19.2ms\n",
      "92:\tlearn: 0.0522635\ttotal: 222ms\tremaining: 16.7ms\n",
      "93:\tlearn: 0.0520373\ttotal: 223ms\tremaining: 14.2ms\n",
      "94:\tlearn: 0.0518088\ttotal: 224ms\tremaining: 11.8ms\n",
      "95:\tlearn: 0.0512336\ttotal: 225ms\tremaining: 9.36ms\n",
      "96:\tlearn: 0.0508851\ttotal: 226ms\tremaining: 6.98ms\n",
      "97:\tlearn: 0.0504355\ttotal: 226ms\tremaining: 4.62ms\n",
      "98:\tlearn: 0.0496341\ttotal: 227ms\tremaining: 2.29ms\n",
      "99:\tlearn: 0.0493009\ttotal: 228ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier(max_depth=4,  min_samples_leaf=20)\n",
    "# clf_dt = clf_dt.fit(X_train, y_train)\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth=4)\n",
    "# clf_rf = clf_rf.fit(X_train, y_train)\n",
    "\n",
    "clf_xgb = XGBClassifier()\n",
    "# clf_xgb = clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "cat_features = [0, 1]\n",
    "clf_cb = CatBoostClassifier(iterations=100, learning_rate=1, depth=4)\n",
    "# clf_cb.fit(X_train, y_train, cat_features)\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('dt', clf_dt), ('rf', clf_rf), ('xgb', clf_xgb), ('catb', clf_cb)], voting='soft')\n",
    "eclf2 = eclf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:06:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "clf_xgb = clf_xgb.fit(X_train, y_train)\n",
    "clf_rf = RandomForestClassifier(max_depth=4)\n",
    "clf_rf = clf_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_for_model = transform_data_for_model(df_test)\n",
    "df_test_for_model = df_test_for_model[['Pclass', 'SibSp', 'Parch', 'Fare', 'Embarked', 'name_part', 'cabin_letter', 'sex_binary', 'age_no_nan']]\n",
    "df_test_for_model = pd.get_dummies(df_test_for_model, prefix=['Embarked','name_part','cabin_letter'], columns=['Embarked','name_part','cabin_letter'])\n",
    "# Жуткий костыль!\n",
    "df_test_for_model['cabin_letter_T'] = 0\n",
    "df_test_for_model['Fare'] = df_test_for_model['Fare'].fillna(df_test_for_model['Fare'].median())\n",
    "df_test_for_model['Survived'] = clf_rf.predict(df_test_for_model[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_for_model[['Survived']].to_csv('result_rf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
